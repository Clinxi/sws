# lecture 1
## LSTM

## transformer

### encoder-decoder
1. 不管输入序列和输出序列长度是什么，中间的「向量 c」长度都是固定的，这也是它的一个缺陷。
2. 不同的任务可以选择不同的编码器和解码器 (RNN，CNN，LSTM，GRU)。
+ Encoder-Decoder 有一个比较显著的特征就是它是一个 End-to-End 的学习算法，以机器翻译为例，可以将法语翻译成英语。这样的模型也可以叫做 Seq2Seq。
### defect
不管输入序列和输出序列长度是什么，中间的「向量 c」长度都是固定的。所以，RNN 结构的 Encoder-Decoder 模型存在长程梯度消失问题，对于较长的句子，我们很难寄希望于将输入的序列转化为定长的向量而保存所有有效信息，即便 LSTM 加了门控机制可以选择性遗忘和记忆，随着所需翻译的句子难度怎能更加，这个结构的效果仍然不理想。

### seq2seq
+ 这种结构最重要的地方在于输入序列和输出序列的长度是可变的。
+ Seq2Seq 强调目的，不特指具体方法，满足输入序列，输出序列的目的，都可以统称为 Seq2Seq 模型。Seq2Seq 使用的具体方法基本都是属于 Encoder-Decoder 模型的范畴。

### attention
+ Attention 就是为了解决信息过长导致信息丢失的问题


## autodecoder
+ 在深度学习中，自动编码器是一种无监督的神经网络模型，它可以学习到输入数据的隐含特征，这称为编码(coding)，同时用学习到的新特征可以重构出原始输入数据，称之为解码(decoding)。
+ 从直观上来看，自动编码器可以用于特征降维，类似主成分分析PCA，但是其相比PCA其性能更强，这是由于神经网络模型可以提取更有效的新特征。除了进行特征降维，自动编码器学习到的新特征可以送入有监督学习模型中，所以自动编码器可以起到特征提取器的作用。
+ reason for introducing autodecoder:好端端的图片为什么要压缩呢?其主要原因是：有时神经网络要接受大量的输入信息, 比如输入信息是高清图片时, 输入信息量可能达到上千万, 让神经网络直接从上千万个信息源中学习是一件很吃力的工作. 所以, 何不压缩一下, 提取出原图片中的最具代表性的信息, 缩减输入信息量, 再把缩减过后的信息放进神经网络学习. 这样学习起来就简单轻松了.

### characteristics of autodecoder:
1. 自动编码器是数据相关的（data-specific 或 data-dependent），这意味着自动编码器只能压缩那些与训练数据类似的数据。比如，使用人脸训练出来的自动编码器在压缩别的图片，比如树木时性能很差，因为它学习到的特征是与人脸相关的。
2. 自动编码器是有损的，意思是解压缩的输出与原来的输入相比是退化的，MP3，JPEG等压缩算法也是如此。这与无损压缩算法不同。
3. 自动编码器是从数据样本中自动学习的，这意味着很容易对指定类的输入训练出一种特定的编码器，而不需要完成任何新工作。

### how to build an autodecoder
+ 搭建编码器，搭建解码器，设定一个损失函数
1. 第一个网络是一个编码器，负责接收输入 x，并将输入通过函数 h 变换为信号 y

$$
y = h(x)
$$

2. 第二个网络将编码的信号 y 作为其输入，通过函数f得到重构的信号 r

$$
r = f(y) = f(h(x))
$$

3. 定义误差 e 为原始输入 x 与重构信号 r 之差，e=x–r，网络训练的目标是减少均方误差（MSE），同 MLP 一样，误差被反向传播回隐藏层。

